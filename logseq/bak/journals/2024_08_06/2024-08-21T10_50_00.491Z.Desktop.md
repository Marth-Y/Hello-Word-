- 一维卡尔曼滤波 #kalman
	- 问题描述：
		- 一只狗在马拉松中移动。脖子上的项圈有一个传感器，传感器的值有误差，但是误差一般很小，如：狗移动了23m，传感器可能会给出22.9m或者23.1m，我们可以使用高斯对其建模。我们预测狗的移动，可能过了头，也可能没过头，也可以使用高斯来建模。
	- 我们可以用高斯来描述对狗的位置的信念。初始我们相信狗在10m的位置，方差为1.
		- ```python
		  # 1. 假设狗的位置的信念符合正态分布
		  from scipy.stats import norm
		  import numpy as np
		  import matplotlib.pyplot as plt
		  
		  
		  gaussion = norm(10, 1)
		  xs = np.arange(4, 16, 0.05)
		  ys = [gaussion.pdf(x) for x in xs]
		  
		  plt.plot(xs, ys)
		  plt.xlim(4, 16)
		  plt.ylim(0, 0.5)
		  plt.show()
		  ```
		- ![one-dimensional-kalman.png](../assets/one-dimensional-kalman_1722958705620_0.png)
		- 从图中可以看出我们对狗的位置并不确定，只能认为狗极有可能在10m的位置，但9~11m的任何位置都有可能。假设我们读取传感器500次，每次返回的值都在8~12之间，以10为中心，我们应该非常确信狗在10附近。
			- ```python
			  # 2. 假设读取传感器500次,所有数值都在10附近:
			  import numpy as np
			  from numpy.random import randn
			  import matplotlib.pyplot as plt
			  
			  # range(500) 生成一个范围对象，这个对象表示从 0 开始到 499 结束的整数序列
			  xs = range(500) 
			  ys = randn(500)*1. + 10.
			  plt.plot(xs, ys)
			  plt.show()
			  print(f'Mean of readings is {np.mean(ys):.3f}')
			  # Mean of readings is 10.004
			  ```
			- ![range-500.png](../assets/range-500_1722959431451_0.png)
			- 假设狗一直静止，我们就说狗在10的位置，方差为1.
	- 使用高斯概率进行追踪
		- tracking是通过预测和更新的循环进行的，我们使用如下方程计算：
			- $$\begin{aligned} 
			  \bar {\mathbf x} &= \mathbf x \ast f_{\mathbf x}(\bullet)\, \, &\text{Predict} \\
			  \mathbf x &= \mathcal L \cdot \bar{\mathbf x}\, \, &\text{Update}
			  \end{aligned}$$
			- $\bar{\mathbf x}$是`prior`，$\mathcal L$是给定$\bar{\mathbf x}$的`likelihood`，$f_{\mathbf x}(\bullet)$是`process model`，$\ast$表示卷积`convolution`，$\mathbf x$粗体表示它是数字的直方图或矢量。
		- 这种方法会产生直方图，这意味着狗可能同时出现在多个地方。此外，对于大型问题，计算速度会很慢。
		- 我们可以使用高斯$\mathcal N(x, \sigma^2)$来替代$\mathbf x$和直方图
			- ![image.png](../assets/image_1722960173363_0.png)
			- 高斯分布的尾部在两边延伸到无穷大，所以它在直方图中包含任意多的条形图。如果这代表了我们对狗在走廊上的位置的信念，那么这个高斯分布覆盖了整个走廊(以及整个宇宙在这个轴上)。我们认为狗很可能在10，但它可能在8、14，或者在极小的概率下，在10$^{80}$。
			- 用高斯替换直方图：
				- $$\begin{array}{l|l|c}
				  \text{discrete Bayes} & \text{Gaussian} & \text{Step}\\
				  \hline
				  \bar {\mathbf x} = \mathbf x \ast f(\mathbf x) & 
				  \bar {x}_\mathcal{N} =  x_\mathcal{N} \, \oplus \, f_{x_\mathcal{N}}(\bullet) &
				  \text{Predict} \\
				  \mathbf x = \|\mathcal L \bar{\mathbf x}\| & x_\mathcal{N} = L \, \otimes \, \bar{x}_\mathcal{N} & \text{Update} 
				  \end{array}$$
				- 其中$\oplus$和$\otimes$表示高斯函数上的未知算子。下标表示$x_\mathcal{N}$是高斯分布。
			- 离散贝叶斯滤波器使用卷积进行预测。我们证明了它使用了总概率定理，以求和的形式计算，所以也许我们可以加上高斯函数。它使用乘法将测量值合并到先验中，所以我们可以将高斯函数相乘。
			- $$\begin{aligned} 
			  \bar x &\stackrel{?}{=} x + f_x(\bullet) \\
			  x &\stackrel{?}{=} \mathcal L \cdot \bar x
			  \end{aligned}$$
			- > This will only work if the sum and product of two Gaussians is another Gaussian. Otherwise after the first epoch $x$ would not be Gaussian, and this scheme falls apart.
	- 使用高斯预测
	- 使用高斯更新
	- Last Source Code:
		- ```python
		  # 1. 假设狗的位置的信念符合正态分布
		  from scipy.stats import norm
		  import numpy as np
		  import matplotlib.pyplot as plt
		  
		  
		  gaussion = norm(10, 1)
		  xs = np.arange(4, 16, 0.05)
		  ys = [gaussion.pdf(x) for x in xs]
		  
		  plt.plot(xs, ys)
		  plt.xlim(4, 16)
		  plt.ylim(0, 0.5)
		  plt.show()
		  
		  # 2. 假设读取传感器500次,所有数值都在10附近:
		  import numpy as np
		  from numpy.random import randn
		  import matplotlib.pyplot as plt
		  
		  # range(500) 生成一个范围对象，这个对象表示从 0 开始到 499 结束的整数序列
		  xs = range(500) 
		  ys = randn(500)*1. + 10.
		  plt.plot(xs, ys)
		  plt.show()
		  print(f'Mean of readings is {np.mean(ys):.3f}')
		  
		  # 提供__repr__函数，使用元组表示高斯函数， g[0]表示均值,g[1]表示方差
		  from collections import namedtuple
		  gaussian = namedtuple('Gaussian', ['mean', 'var'])
		  gaussian.__repr__ = lambda s: f'𝒩(μ={s[0]:.3f}, 𝜎²={s[1]:.3f})'
		  # 从而可以使用g1 = gaussian(3.4, 10.1)
		  g1 = gaussian(3.4, 10.1)
		  g2 = gaussian(mean=4.5, var=0.2**2)
		  print(g1)
		  print(g2)
		  # 可以使用以下方法访问均值和方差
		  g1.mean, g1[0], g1[1], g1.var
		  
		  
		  
		  # 以下是高斯函数的predict函数实现,其中pos和movement是高斯元组，格式为(mean,var):
		  def predict(pos, movement):
		      return gaussian(pos.mean + movement.mean, pos.var + movement.var)
		  pos = gaussian(10., .2**2)
		  move = gaussian(15., .7**2)
		  predict(pos, move)
		  
		  # update实现
		  def gaussian_multiply(g1, g2):
		      mean = (g1.var * g2.mean + g2.var * g1.mean) / (g1.var + g2.var)
		      variance = (g1.var * g2.var) / (g1.var + g2.var)
		      return gaussian(mean, variance)
		  
		  def update(prior, likelihood):
		      posterior = gaussian_multiply(likelihood, prior)
		      return posterior
		  
		  # test the update function
		  predicted_pos = gaussian(10., .2**2)
		  measured_pos = gaussian(11., .1**2)
		  estimated_pos = update(predicted_pos, measured_pos)
		  estimated_pos
		  
		  
		  ```